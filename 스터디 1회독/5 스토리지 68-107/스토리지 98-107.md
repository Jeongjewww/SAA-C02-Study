[스토리지 2- 98]

**문제의 Keywords** : #비디오 저장 #서버 부하 최소화(=캐싱 같은 서비스)

- 해설
    
    A: 비디오를 저장하는 저장소에 대한 설명이 나오지 않음 (X)
    B. 서버 부화 최소에 대한 조건 X 
    C. 정답이다 
    D. We're not running anything on premise.
    
    a: 비디오를 스토리지에 저장해야하는데 데이터베이스에 대한 정보가 없음 → 만약 RDS가 DB라면 비디오 저장에 문제가 있음 
    
    b: **EFS 도입(-스토리지의 탄력적인 확장/축소)** 많으로는 서버 부하 최소화에 대한 방안이 없음 
    
    c: CDN을 사용하여 서버 부하를 최소화하고 S3+CDN 조합이므로 비디오 저장이 가능하고 OAI로 S3 URL로 접근을 하지 못하게 제어하면서 부하 조절에 도움이 될 수 있다
    
    d: 온프레미스가 아니므로 storage gateway와 연관 없음
    
- **💫 Cloud Front (CDN)**
    
    [https://aws.amazon.com/ko/cloudfront/streaming/](https://aws.amazon.com/ko/cloudfront/streaming/)
    
    콘텐츠가 안전하게 저장되고 사용자가 요청한 형식으로 제공할 수 있게 되면 다음 단계는 Amazon CloudFront를 통한 글로벌 전송입니다. Amazon 콘텐츠 전송 네트워크는 짧은 지연 시간과 높은 처리량으로 비디오를 전송하기 위해 엣지에 콘텐츠를 캐시합니다. 이 서비스는 원하는 양의 비디오를 제공할 수 있는 확장성을 갖추고 있습니다. 사용량에 따라 지불하는 간편한 요금제를 통해 예기치 못한 수요 급증을 처리할 수 있습니다(자세한 내용은 [CloudFront 요금제](https://aws.amazon.com/ko/cloudfront/pricing/)
     참조).
    
- ‼ **Redis용 Amazon Elastic Cache 란?**
    
    Redis용 Amazon ElastiCache는 인터넷 규모의 실시간 애플리케이션을 지원할 수 있도록 1밀리초 미만의 지연 시간을 제공하는 놀랍도록 빠른 인 메모리 데이터 스토어입니다.
    

---

[스토리지 2- 99]

**문제의 Keywords** : #처음 30일 동안 자주 엑세스 → S3생명주기 정책 #그 이후 거의 액세스 X #이전 객체는 영구보관 1주일 이내 검색 #현재 객체 5분 이내 검색  #가용성/내구성 #비용 효율

- 해설
    
    우선 n일간 자주 액세스 후 거의 액세스 x → s3생명주기 관련 이구나! 그리고 현재 객체와 이전 객체 검색 시간이 다르다 → 두 객체 간 생명주기에 차이를 둬서 비용을 아껴야 한다! 또한 영구보존이기 때문에 → Glacier에 힘을 실었다 
    
    a: 둘 다 같은 생명주기 → 비용효율 X
    
    b: 현재 객체는 Glacier(Glacier Expedited retrieval-검색 속도 1-5분 이내), 이전 객체는 Glacier Deep Archive (최소 12시간)
    
    c: Standard IA 가 틀린 건 아니지만, Glacier가 더 비용 효율적
    
    d: One Zone-IA + Deep Archive ⇒ B가 가장 비용 효율적 
    

**💫 S3의 다양한 스토리지 클래스** 

[객체 스토리지 클래스 - Amazon S3](https://aws.amazon.com/ko/s3/storage-classes/)

---

[스토리지 2- 100] 338

**문제의 Keywords** :  #mission-critical application #단일 리전에서 ASG 실행 #AWS Aurora→ 배포 가용성 안 높아! #데이터베이스의 가용성 향상을 원해

- 해설
    
    

[Amazon Aurora의 고가용성](https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/AuroraUserGuide/Concepts.AuroraHighAvailability.html)

---

[스토리지 2- 101]

**문제의 Keywords** : #문서 암호화 #회사가 암호화 프로세스 관리하고 싶지 않아

- 해설
    
    기본 키를 관리하고 싶지만, 그 프로세스는 관심 끄고 싶다! 
    
    답은 A /E
    
    SSE-C(고객 제공 암호화 키)로 기본기를 집접 생성/관리 할 수 있고, SSE-KMS로 내 키를 KMS에 올리고 해당 프로세스를 자동으로 관리 할 수 있음 
    
    A: [https://docs.aws.amazon.com/ko_kr/ko_kr/AmazonS3/latest/userguide/ServerSideEncryptionCustomerKeys.html](https://docs.aws.amazon.com/ko_kr/ko_kr/AmazonS3/latest/userguide/ServerSideEncryptionCustomerKeys.html)
    
    B: 클라이언트 측 암호화는 사용자가 프로세스를 관리해야 함 
    
    [암호화를 사용하여 데이터 보호](https://docs.aws.amazon.com/ko_kr/ko_kr/AmazonS3/latest/userguide/UsingEncryption.html)
    
    C: SSE-S3는 회사가 기본 키 관리를 할 수 없음 (S3가 해서) 
    
    D: 최대 문서 크기는 32KB 이다 (X) 
    
- 💫**서버 측 암호화**
    
    Amazon S3에서 SSE-S3, SSE-C 또는 SSE-KMS 등 세 가지 모드의 서버 측 암호화를 사용하여 저장된 데이터를 보호할 수 있습니다
    
    - SSE-S3 : Amazon S3가 데이터와 암호화 키를 관리하도록 요구
    - SSE-C : 사용자에게 암호화 키 관리를 요구
    - SSE-KMS :  AWS가 데이터 키를 관리해야 하지만 [AWS KMS keys](https://docs.aws.amazon.com/ko_kr/kms/latest/developerguide/concepts.html#kms_keys)는 AWS KMS에서 관리함

---

[스토리지 2- 102]344

**문제의 Keywords** : #웹계층의 디비 접근에 문제가 있음 #DB→프라이빗 서브넷 RDS #EC2 ASG→multi AZ & 퍼블릭 서브넷 #다른 값들 다 디폴트 값

- 해설
    
    

---

[스토리지 2- 103]

**문제의 Keywords** : #엔지니어링 도면 저장(이미지/미디어) #캐싱 지원 #페타바이트 데이터 저장 

#스토리지+캐싱조합

- 해설
    
    엔지니어링 도면이라는 이미지(파일)을 저장하고 지연 최소를 위해 캐싱을 지원해야 한다 → CDN을 사용하고 싶다!
    
    **A:** CDN을 사용하는 A가 답이다 S3→ 무한 확장 가능(페타바이트 지원)
    
    ![2-103-1](https://user-images.githubusercontent.com/70079416/185461807-e04db01b-b4a9-444e-9f82-ae6b1a0b2ead.png)
    
    B: Glacier 생명주기나 영구 보존이라는 키워드가 없고 지연 시간 최소화를 원함 답 **(X)**
    
    C: EBS 볼륨 16TB or 64TB까지 지원됨 **(X)**
    
    ![2-103-2](https://user-images.githubusercontent.com/70079416/185461803-eb104870-b3bf-453e-9855-fdcc92eafec4.png)
    
    출처: [https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/ebs-volume-types.html](https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/ebs-volume-types.html)
    
    D: 온프레미스 환경이 아니므로 STORAGE gATEWAY **(X)**
    

---

[스토리지 2- 104]

**문제의 Keywords** : #140TB & 100Mbps 대역폭 #마이그레이션 #마이그레이션 시 변경 원치 않아!

- 해설
    
    A: Snowball 을 이용하여 대용량의 데이터를 마이그레이션 하고, EFS를 스토리지(Linux 지원)로 사용한다. 
    
    B: 마이그레이션 도중 변경을 원치 않음 대역폭 제한 시 snowball을 사용 
    
    C: EBS → 최대 용량이 16/6TB 이므로 조건 충족X  (X)
    
    D: 게이트웨이 그 자체는 스토리지로 사용할 수 없음 (X)
    

**Snowball vs DataSync** 

- **DataSync**

![2-104-1](https://user-images.githubusercontent.com/70079416/185461802-0cce083b-bcb9-4610-a138-b5d463f45ea8.png)

- **Snowball**
    
    ![2-104-2](https://user-images.githubusercontent.com/70079416/185461797-a81f78aa-f7e8-4311-8b34-f3f26c588188.png)
    

---

[스토리지 2- 105]

**문제의 Keywords** : #비용 최소화 #정적 웹사이트  #99% 이상의 가용성

- 해설
    
    정적 웹 사이트 → S3 를 말함 기본적으로 99.99% 가용성 제공 & 버저닝은 복구를 위한 키워드(가용성 측면이 아님) 그래서 비용 효율 적인 것은 **A**이다 
    
    ![2-105-1](https://user-images.githubusercontent.com/70079416/185463196-ddaca8d5-9d37-4abe-8812-ea57b0bcb8a3.png)
    

[객체 스토리지 클래스 - Amazon S3](https://aws.amazon.com/ko/s3/storage-classes/)

---

**[스토리지 2- 106]**

**문제의 Keywords** : #기계 학습 솔루션 #S3에서 대용량 데이터 set 다운(사용자는 동일 리전 EC2에서 다운) #여러 사용자가 동시에 동일 데이터 사용 #시간 최소화 솔루션 원해!

- 해설
    
    A: 사용자가 EC2를 통한 다운로드를 원함 (X)
    
    B: 사용자가 EC2를 통한 다운로드를 원함 (X)
    
    C: EFS → 자동 확장 가능한 공유 파일 스토리지 & 짧은 지연시간 제공 + AWS DataSync 로 빠른 전달 가능 **(근데 마이그레이션이라는 단어가 거슬린다! but datasync가 EFS, S3 간 데이터 이동 지원)**
    
    ![2-105](https://user-images.githubusercontent.com/70079416/185462880-aaae8f0a-80cc-4d8a-86b3-752920ed2cfb.png)
    
    [AWS DataSync란 무엇입니까?](https://docs.aws.amazon.com/ko_kr/datasync/latest/userguide/what-is-datasync.html)
    
    D: 대용량의 데이터Set  + 여러 사용자의 동일 데이터 동시 접근 → EBS에 맞지 않음
    
- 💫Transfer Acceleration
    
    : 클라이언트와 S3 버킷 간의 **장거리 파일 전송**을 파일을 **빠르고 쉽고 안전하게 전송**할 수 있는 **버킷 수준 기능**입니다. Transfer Acceleration은 Amazon CloudFront에서 전 세계에 분산된 엣지 로케이션을 활용합니다.
    
    ![2-106](https://user-images.githubusercontent.com/70079416/185462873-779fa2a2-ca17-4373-85db-a61acd5f1716.png)
    
- **S3 Intelligent-Tiering**
    
    **데이터 액세스 패턴이 변경**될 때 성능에 대한 영향이나 **운영 오버헤드 없이 스토리지 비용을 자동으로 최적화**하려는 고객을 위해 설계된 신규 **Amazon S3 스토리지 클래스**입니다. S3 Intelligent-Tiering은 액세스 패턴이 변경될 때 두 액세스 티어(Frequent Access 및 Infrequent Access) 간에 데이터를 이동시켜 비용을 자동으로 절약해 주는 최초의 클라우드 객체 스토리지 클래스로서, 액세스 패턴을 알 수 없거나 액세스 패턴이 변경되는 데이터에 적합합니다.
    

---

**[스토리지 2- 107]**

**문제의 Keywords** : #전세계 사용자 #중앙 집중식 #업로드 속도 높이고자함

- 해설
    
    전세계 사용자 → 엣지 로케이션 서비스 사용 
    
    중앙 집중식 → Transfer Acceleration 사용! 
    
    가속화된 업로드 → Accelerate Endpoint 사용
    
    - **Transfer Acceleration**에서 **가속 엔드포인트(Accelerated endpoint)**는 버킷의 Transfer Acceleration 엔드포인트를 표시합니다. 이 엔드포인트를 사용하여 버킷과 주고받을 때 **가속화된 데이터 전송에 액세스**할 수 있습니다.
    
    그러므로 답은 D!
    
- 💫Transfer Acceleration
    
    : 클라이언트와 S3 버킷 간의 **장거리 파일 전송**을 파일을 **빠르고 쉽고 안전하게 전송**할 수 있는 **버킷 수준 기능**입니다. Transfer Acceleration은 Amazon CloudFront에서 전 세계에 분산된 엣지 로케이션을 활용합니다.
    
    ![2-107](https://user-images.githubusercontent.com/70079416/185462863-1924d6ac-3691-43ea-a7ab-714284e00d96.png)