[보안 5-58]

**문제의 Keywords** : #EC2 인스턴스 IAM역할 나열을 위한 검색 방법 

- 해설
    
    보자마자 내가 풀 수 있는 문제가 아니라 생각함 → 개념 + 답이 딱 나와있는 문제
    
    EC2에서 IAM 권한 정보 검색을 위한 명령어는 A이다 *여기서 meta-data는 인스턴스에 대한 데이터를 말함 
    
    **인스턴스의 Role 정보**  
    $ curl [http://169.254.169.254/latest/meta-data/iam/info](http://169.254.169.254/latest/meta-data/iam/info)
    
    ![5-58](https://user-images.githubusercontent.com/70079416/185479662-c7bd47a7-daa6-4226-a675-8b2a81efcfa4.png)
    
    [Troubleshooting IAM and Amazon EC2](https://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_iam-ec2.html)
    
    [https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html](https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html)
    
    b: 인스턴스 사용자의 데이터(user-data) 중 iam정보 검색 
    
    c: 인스턴스 자격 증명 검색을 위한 명령어
    
    d: 인스턴스 프로파일 정보 불러오기 
    
    ![5-58-1](https://user-images.githubusercontent.com/70079416/185479659-051ff398-a74e-4f3a-8735-0a6b8dccd9ce.png)
    
    `인스턴스 프로파일은 EC2 인스턴스를 구분하고 그 인스턴스에 권한을 주기 위한 개념입니다.`
     → 인스턴스 프로파일은 역할을 위한 컨테이너로서 인스턴스 시작 시 EC2 인스턴스에 역할 정보를 전달하는 데 사용합니다.
    

---

[분석 5-1]

**문제의 Keywords** : #보고서 쿼리 및 분석 제공 #확장 가능 및 비용 효율  

- 해설
    
    우선 Organizations가 조직의 관리자로서 조직의 계정을 통합 및 운영하는 서비스이므로 C,D는 제외시킴! kinesis + EMR이냐 S3 + Athena이냐 인데 실시간이라는 말이 없어서 B가 맞겠다 생각을 하고 찾아봄!
    
    → 결제 및 사용 보고서를 수신하려면 S3버킷이 있어야 하고 해당 내용을 쿼리하기 위해서는 Athena를 사용한다고 함! 
    
    ![6-1-1](https://user-images.githubusercontent.com/70079416/185479657-e85758d6-9f4a-49eb-aecc-e640324c288a.png)
    
    ![6-1-2](https://user-images.githubusercontent.com/70079416/185479656-255d5ba9-5f56-44d2-8008-2052ea3548cb.png)
    
    [](https://www.megazone.com/techblog_190812_https-aws-amazon-com-ko-blogs-aws-cost-management-querying-your-aws-cost-and-usage-report-using-amazon-athena/)
    
    [Amazon Athena 비용 및 사용 보고서 쿼리](https://docs.aws.amazon.com/ko_kr/cur/latest/userguide/cur-query-athena.html)
    

---

[분석 5-2]

**문제의 Keywords** : #웹사이트 호스팅 #실시간 클릭 행동 보고서 제공 

- 해설
    
    키포인트는 실시간 데이터 처리 및 분석이므로 → Kinesis가 있는 B가 답이다. 
    
    [Amazon Kinesis](https://aws.amazon.com/ko/kinesis/)
    
    → 실시간 스트리밍 데이터를 손쉽게 수집, 처리 및 분석할 수 있으므로 적시에 통찰력을 확보하고 새로운 정보에 신속하게 대응할 수 있습니다. Amazon Kinesis는 모든 규모의 스트리밍 데이터를 비용 효율적으로 처리할 수 있는 핵심 기능과 더불어 애플리케이션 요구 사항에 가장 적합한 도구를 선택할 수 있는 유연성을 제공합니다.
    
    a: 실시간 데이터 분석 및 처리와 관계 없음 (X)
    
    ![6-2](https://user-images.githubusercontent.com/70079416/185479652-3176ac06-e83f-41ce-9f5b-ce3aacf83ca4.png)
    
    c: s3에 실시간 데이터를 저장 >> 실시간 보고서 제공 지원 안 함 (X)
    
    d: SQS + RDS(MySql) >> 말이 안됨 실시간 데이터를 관계형 DB에? (X)
    

---

[분석 5-3]

**문제의 Keywords** : #오버헤드 적게 # 일부 수동 승인 필요 → 여러 람다 기능을 응답형 서버리스 애플리케이션으로 결합 원함 

- 해설
    
    뭔가 여러 람다로 정의되어 있는 기능들을 하나로 오버헤드 적게 통틀어 관리하고 싶다는 느낌
    
    a: [AWS StepFunction](https://aws.amazon.com/ko/step-functions/?step-functions.sort-by=item.additionalFields.postDateTime&step-functions.sort-order=desc) (O)
    
    → **시각적 워크플로우를 사용해 분산 애플리케이션 및 마이크로서비스의 구성 요소를 손쉽게 조정**하도록 해주는 **서버리스 웹 서비스**
    
    ⬇**사례 예제 블로그** 
    
    [AWS step function](https://velog.io/@daeyoon/AWS-step-function)
    
    ![6-3](https://user-images.githubusercontent.com/70079416/185479645-3630b353-b734-4811-8e00-c43eb323e582.png)
    
    b: [AWS Glue](https://aws.amazon.com/ko/glue/?whats-new-cards.sort-by=item.additionalFields.postDateTime&whats-new-cards.sort-order=desc) (X)
    
    → 분석, 기계 학습 및 애플리케이션 개발을 위해 **데이터를 쉽게 탐색, 준비, 그리고 조합할 수 있도록 지원하는 서버리스 데이터 통합 서비스입니다.** AWS Glue에서는 데이터 통합에 필요한 모든 기능을 제공하므로, 몇 개월이 아니라 몇 분 안에 데이터 분석을 시작하고 해당 내용을 활용할 수 있습니다. 데이터 통합 서비스로 람다 함수 통합 관리 지원을 하진 않음
    
    c: Amazon SQS (X)
    
    → 해야 할 일을 나중에 처리하거나, 다른 시스템이 처리 할 수 있도록 하기 위한 **비동기 메시징 서비스** 요구사항과 관련 없음 
    
    d: [AWS EventBridge](https://velog.io/@techy-yunong/AWS-EventBridge-concept) (X)
    → **EDA(Event Driven Architecture)**를 구성하는데 도움을 주는 **AWS의 서버리스 서비스**이다. AWS 서비스 뿐만 아니라 SaaS 서비스, 개인 어플리케이션에서 보내는 이벤트(데이터)를 받아, 원하는 SNS나 lambda와 같은 타겟으로 보내주는 역할을 한다. 문제 요구사항과 관련 없음 
    

---

[분석 5-4]

**문제의 Keywords** : #S3의 csv데이터 #SQL쿼리 수행 #가장 비용 효율적

- 해설
    
    **답은 D**
    
    우선, SQL 쿼리 실행이라 Redshift랑 athena가 생각났고 redshift는 뭔가 데이터 저장소 같아서 s3+sql쿼리니까 ATHENA를 골랐음 근데 둘 다 분석을 제공해 준다 해서 비용의 측면에서 따져봄! 
    
    **AWS Athena Pricing** 
    
    → Athena costs **$5 per TB** of compressed **data scanned**. While you incur **no additional costs for DDL statements or failed queries, standard charges of other** AWS resources.
    
    **AWS RedShift Pricing** 
    
    Amazon Redshift pricing is mainly **calculated on the amount of cluster resources consumed hourly.**
    
    따라서, Athena가 Redshfit 보다 비용 효율적임 ⬇ 참고자료 
    
    b: **[Redshfit](https://aws.amazon.com/ko/redshift/)**
    
    **전용 리소스 세트와 무제한 확장성**을 통해 **Redshift는 더 높은 성능을 위한 선택**이 쉽게 됩니다. 또한 **클러스터와 인스턴스를 쉽게 추가**할 수 있어 동시 쿼리 처리를 위한 Redshift의 **더 높은 계산 용량을 제공**
    
    d: **[Athena](https://aws.amazon.com/ko/athena/?whats-new-cards.sort-by=item.additionalFields.postDateTime&whats-new-cards.sort-order=desc)**
    
    **비용 효율**적이면서도 강력한 **쿼리 플랫폼을 제공**하는 무작위 **수동 분석에 권장**됩니다.
    
    [AWS Athena Pricing vs. AWS Redshift Pricing Comparison | Upsolver](https://www.upsolver.com/blog/aws-athena-pricing-redshift-comparison)
    
    a: Amazon EMR (Amazon Elastic MapReduce)  (X)
    
    → 빅 데이터 프레임워크 실행을 간소화하는 관리형 클러스터 플랫폼
    

---

[분석 5-5]

**문제의 Keywords** : #기밀정보 in S3 #s3버킷의 일부 객체가 삭제됨 → 감사자에게 객체를 삭제한 사람에 대한 정보를 제공해야 함 

- 해설
    
    a: cloudWatchLogs filter → 로그 그룹에서 Amazon S3 버킷으로 로그 데이터를 내보내서 이 데이터를 사용자 지정 처리 및 분석에 사용하거나 다른 시스템에 로드할 수 있음 해당 삭제 건에 대해서 정보를 찾을 수 있는 것은 아닌 것 같고 추출해서 보내는 것만 가능한 것 같음 (X)
    
    [Amazon S3로 로그 데이터 내보내기](https://docs.aws.amazon.com/ko_kr/AmazonCloudWatch/latest/logs/S3Export.html)
    
    b: Athena로 cloudTrailLogs 쿼리 → 
    
    s3버킷에서 삭제나 누락된 객체를 추적하려면, CloudTrail 로그를 들여다 봐야하고 그 중 쓰기 쿼리를 식별하기 위해 Athena를 사용함
    
    ![6-5](https://user-images.githubusercontent.com/70079416/185479637-dcdd1f94-8e5d-46ff-a625-2314676646ef.png)
    
    [Amazon S3 버킷에서 삭제되었거나 누락된 객체 감사](https://aws.amazon.com/ko/premiumsupport/knowledge-center/s3-audit-deleted-missing-objects/)
    
    [CloudTrail 이벤트 기록에서 S3 객체 수준 이벤트 찾기](https://aws.amazon.com/ko/premiumsupport/knowledge-center/find-cloudtrail-object-level-events/)
    
    [c: Trust Advisor (X)](https://aws.amazon.com/ko/premiumsupport/technology/trusted-advisor/)
    
    → 비용 절감, 가용성 및 성능 향상, 보안 개선에 도움이 되는 일련의 모범 사례 점검 항목 및 권장 사항을 제공 
    
    d: [AWS Config](https://aws.amazon.com/ko/config/) (X)
    
    → AWS **리소스 구성을 측정, 감사 및 평가할 수 있는 서비스**입니다. Config는 AWS 리소스 구성을 지속적으로 모니터링 및 기록하고, 원하는 구성을 기준으로 기록된 구성을 자동으로 평가
    

---

[분석 5-6]

**문제의 Keywords** : #확장 가능한 거의 실시간 솔루션 # 짧은 검색을 위해 저장 전 민감한 데이터 제거 위해 트랜잭션을 처리

- 해설
    
    실시간 처리 + 확장 가능이라해서 Kinesis다 하고 A와 D를 제거함 
    
    b: Kinesis Data Firehose
    
    c: Kinesis Data Streams
    
    두개의 차이는 이것인데! Data Firehose는 DynamoDB에 접근/저장 할 수 없기 때문에 
    
    **답은 C이다!** 
    
    **첨언 From ExamTopics** ([https://www.examtopics.com/discussions/amazon/view/46763-exam-aws-certified-solutions-architect-associate-saa-c02/](https://www.examtopics.com/discussions/amazon/view/46763-exam-aws-certified-solutions-architect-associate-saa-c02/))
    
    >> B is out. Kinesis, can only store in DynamoDB through Lambda. Even if it was possible to store directly in DynamoDB the option is flawed, because the document is being stored before removing the sensitive data.
    

---

[분석 5-7]

**문제의 Keywords** : #AWS에 분석 어플리케이션 호스팅 중 #300MB 데이터 생성(JSON) #재해복구 솔루션 원하고 → 밀리초단위 엑세스 & 30일 보관해야함 #비용 효율!

- 해설
    
    **답은 A 아니면 D 같은데... 모르겠다!** 
    
    재해 복구솔루션 + 밀리초 단위 엑세스 + 30일 보관 
    
    a:Amazon ES → 현재 [OpenSearch Service](https://aws.amazon.com/ko/opensearch-service/?nc=bc&pg=gs)로 업그레이드 됨 (O)
    
    → **최대 페타바이트 규모의 텍스트 및 비구조화 데이터의 검색 시각화 및 분석,** 데이터 모델은 **JSON을 사용**하고 있어서 요청 및 응답을 다 JSON을 사용함 
    
    b: S3 Glacier (X)
    
    → 즉각적인 액세스가 필요하지 않지만 비용 없이 큰 데이터 집합을 검색하는 유연성이 필요한 아카이브 데이터(예: 백업 또는 재해 복구 사용 사례)의 경우 **5~12시간의 무료 대량 검색 또는 몇 분 내 검색을 지원**하는 S3 Glacier Flexible Retrieval(이전의 S3 Glacier)
    
    c: S3 Standard (X)
    
    → 자주 액세스하는 데이터(한 달에 한 번 이상), 밀리초 단위의 검색 액세스 보관 기간이 따로 잊지는 않음 but,  json 데이터를 저장하려면 lambda를 사용해서 변환을 해줘야함 
    
    d: [PostgreSQL용 RDS](https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/CHAP_Storage.html) (O)
    
    → 지연시간 밀리초, JSON 형식 저장을 지원함 , 30일 보관 여부는 모름
    

---

[분석 5-8]

**문제의 Keywords** : #온프레미스 데이터 원본에서 데이터 수집 (json, 1MB/s) #거의 실시간으로 쿼리 →최소한의 데이터 손실로 확장 가능한 실시간 데이터 쿼리 제공 솔루션 

- 해설
    
    실시간 쿼리 분석 → Kinesis 아니냐며... **답은 A**
    
    a: [Amazon Kinesis Data Streams](https://aws.amazon.com/ko/kinesis/data-streams/)  (O)
    
    →모든 규모의 데이터 스트림을 쉽게 캡처, 처리 및 저장할 수 있는 서버리스 스트리밍 데이터 서비스
    
    ![6-8](https://user-images.githubusercontent.com/70079416/185479629-1d2776fb-71ee-4392-85a0-65f6df4ba295.png)
    
    b: Kinesis Data Firehose (X)
    
    →스트리밍 데이터를 안정적으로 캡처하고 변환하여 데이터 레이크, 데이터 스토어, 분석 서비스에 전달하는 추출, 변환 로드 서비스 ⇒ 추출 및 변환 담당이고 Redshift로 쿼리한다.
    
    위 문제에서 처럼 고성능을 위한거면 redshift지만, 실시간 분석에 더 초점이 있으므로 (X)
    
    c: EC2 인스턴스 스토어에 저장 후 S3를 대상으로 라고 하여 제낌 → 오버스펙 느낌 
    
    d: 실시간 쿼리, 데이터 분석인데 EBS?? (X)
    

---

[분석 5-9]

**문제의 Keywords** : #반정형 데이터 수신 #빅데이터처리 프레임워크 #고성능 #BI 및 SQL쿼리 

- 해설
    
    빅데이터 처리 및 분석 → EMR이다!
    
    SQL queries and business intelligence → Redshift 이므로  
    
    **답은 B!** 
    
    [빅 데이터 플랫폼 - Amazon EMR - Amazon Web Services](https://aws.amazon.com/ko/emr/)
    

[https://www.examtopics.com/discussions/amazon/view/29738-exam-aws-certified-solutions-architect-associate-saa-c02/](https://www.examtopics.com/discussions/amazon/view/29738-exam-aws-certified-solutions-architect-associate-saa-c02/)
