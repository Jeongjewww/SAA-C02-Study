### 2-2 - A,C 중 고민하다가 A

키워드: 데이터 센터 간 대용량 & 안전하게 전송, `site-to-site VPN` 90% 활용됨 

- [site-to-site VPN](https://docs.aws.amazon.com/ko_kr/vpn/latest/s2svpn/VPC_VPN.html) : 온프레미스 장비와 VPC 간의 보안 연결
    - 가상 프라이빗 게이트웨이
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/3065a42b-622c-4657-8157-fab14c6f0a55/Untitled.png)
    
    - 전송 게이트웨이
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/a201419f-583a-4638-ad71-41348f417f23/Untitled.png)
    

**A.** VPC 엔드포인트가 있는 [AWS DataSync](https://docs.aws.amazon.com/ko_kr/datasync/latest/userguide/what-is-datasync.html)

온프레미스 스토리지 시스템 간의 데이터 이동을 단순화, 자동화 및 가속화는 온라인 데이터 전송 서비스

*→ 링크 내에 ‘사용사례’를 보면 적절한 것 같음..*

B. AWS 직접 연결

→ site-to-site vpn 활용 X

**C.** AWS [Snowball Edge](https://docs.aws.amazon.com/ko_kr/snowball/latest/developer-guide/whatisedge.html) 스토리지 최적화

→ 로컬 환경과 aws 클라우드 환경 간에 데이터를 전송하는 것

→ 지역 운송업체를 통해 어플라이언스의 데이터를 운송하는 방식 → 인터넷보다 빠른 속도로 데이터를 전송

*→ 물리적으로 전송하는 개념인데 site-to-site vpn을 잘 활용하지 못하는 것 같아 오답인 것 같기도 하다.*

D. AWS [스토리지 게이트웨이](https://docs.aws.amazon.com/ko_kr/storagegateway/latest/userguide/WhatIsStorageGateway.html)

→ 온프레미스 소프트웨어 어플라이언스를 클라우드 기반 스토리지에 연결→ Amazon Web Services Cloud에 데이터를 저장하여 데이터 보안, 확장 가능, 비용 효율적 스토리지를 구현

→ 데이터 센터 간 데이터 대량 전송과 무관

### 2-3

키워드: 온프레미스 데이터 센터, 기존 애플리케이션 환경 유지, 데이터 분석 및 시각화 목적

A. [Amazon RedShift](https://docs.aws.amazon.com/ko_kr/redshift/latest/mgmt/welcome.html) : 데이터 웨어하우스 서비스

→ 쿼리를 적용할 데이터베이스 스타일에 적합한 서비스

**B.** [파일용 AWS Storage Gateway](https://docs.aws.amazon.com/ko_kr/storagegateway/latest/userguide/WhatIsStorageGateway.html#s3-file)

[Amazon S3 File Gateway](https://aws.amazon.com/ko/storagegateway/file/s3/)를 사용하면 Amazon S3 클라우드 스토리지에 객체로 파일 데이터를 저장하여 데이터 레이크, 백업 및 기계 학습 워크플로를 지원할 수 있습니다. ([설명 링크](https://aws.amazon.com/ko/storagegateway/file/))

*→ 기존 애플리케이션 환경을 유지하면서(S3 스토리지에 객체로 파일을 저장하니까) 데이터 분석 용도로 사용될 수 있음*

C. [Amazon EBS](https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/AmazonEBS.html)(Amazon Elastic Block Store) : EC2 인스턴스에 사용할 수 있는 블록 수준 스토리지 볼륨 제공

→ 데이터에 빠르게 액세스하고 장기적으로 지속해야 하는 경우에 적합

→ 문제 조건에 따르면 빠르게 액세스는 필요 X

D. [Amazon EFS](https://docs.aws.amazon.com/ko_kr/efs/latest/ug/whatisefs.html)(Amazon Elastic File System) : 

애플리케이션을 중단하지 않고 온디맨드 방식으로 페타바이트 규모까지 확장되도록 구축되어, 사용자가 파일을 추가하고 제거할 때 자동으로 확장/축소되므로 데이터 증가에 맞춰 용량을 프로비저닝 및 관리할 필요가 없습니다. 

### 2-4 <별>

- 현재 상황: 단일 VPC 내 여러 가용영역, EC2 인스턴스에서 미디어 스토어
- 요구사항: `모든 EC2 인스턴스 간 데이터 공유`, `VPC 내에서만 공유`

A. Amazon S3 버킷을 생성하고 각 인스턴스의 애플리케이션에서 서비스 API 호출

→ 서비스 API 호출하게 되면 `VPC 내에서만 공유` 조건 X

B. Amazon S3 버킷을 생성하고 탑재된 볼륨으로 액세스하도록 모든 인스턴스를 구성

*→ 볼륨을 사용할 거면 EBS 볼륨을 사용하는 것이 더 효과적일 것으로 추정*

[참고] **[Amazon EC2와 함께 Amazon S3 사용](https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/AmazonS3.html) 사례**

**C. [**Amazon Elastic Block Store(EBS) 볼륨](https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/ebs-volumes.html) 구성하고 모든 인스턴스에 마운트

→ EBS가 EC2 인스턴스에 사용할 수 있는 블록 수준 스토리지 볼륨 제공, 여러 EBS 볼륨을 단일 인스턴스에 연결할 수 있습니다. 볼륨 및 인스턴스는 동일 가용 영역에 위치해야 합니다. 볼륨 및 인스턴스 유형에 따라 다중 연결을 사용하여 볼륨을 여러 인스턴스에 동시에 탑재할 수 있습니다.

D. [Amazon EFS](https://docs.aws.amazon.com/ko_kr/efs/latest/ug/whatisefs.html) (Amazon Elastic File System) 파일 시스템을 구성하고 모든 인스턴스에 탑재

→ `EC2 인스턴스 간 데이터 공유` 와 무관

### 2-5

키워드: `승인된 사용자`, 사용자 도달범위 확장, `콘텐츠 보이는 모바일 앱`

A. 퍼블릭 Amazon S3 버킷에 콘텐츠 게시. [AWS Key Management Service](https://docs.aws.amazon.com/ko_kr/kms/latest/developerguide/overview.html) (KMS) 키를 사용하여 콘텐츠 스트리밍

→ 데이터를 보호하는 데 사용하는 암호화 키를 쉽게 생성하고 제어할 수 있게 해주는 관리형 서비스

→ 데이터 암호화 와는 무관

B. 모바일 앱과 AWS 환경 간에 [IPsec VPN(=Site-to-Site VPN)](https://docs.aws.amazon.com/ko_kr/vpn/latest/s2svpn/VPC_VPN.html) 설정하여 콘텐츠 스트리밍

→ 서로 다른 네트워크를 연결하기 위한 서비스. `승인된 사용자` 조건 불충분

**C.** Amazon [CloudFront](https://docs.aws.amazon.com/ko_kr/AmazonCloudFront/latest/DeveloperGuide/Introduction.html) 사용하여 [서명된 URL](https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/PresignedUrlUploadObject.html)을 제공하여 콘텐츠 스트리밍

→ CloudFront를 통해 서비스하는 콘텐츠를 사용자가 요청하면 지연 시간이 가장 낮은 엣지 로케이션으로 요청이 라우팅되므로 가능한 최고의 성능으로 콘텐츠가 제공됩니다. 

→ `콘텐츠 보이는 모바일 앱` 조건 충족

→ 미리 서명된 URL의 생성자가 해당 객체에 대한 액세스 권한을 보유할 경우, 미리 서명된 URL은 URL에서 식별된 객체에 대한 액세스를 부여합니다.

→ `승인된 사용자`에게만 presigned URL을 제공하여 콘텐츠를 볼 수 있도록 할 수 있음

D. 모바일 앱과 AWS 환경 간에 [AWS Client VPN](https://docs.aws.amazon.com/ko_kr/vpn/latest/clientvpn-admin/what-is.html)을 설정하여 콘텐츠 스트리밍

→ Client VPN에서는 OpenVPN 기반 VPN 클라이언트를 사용하여 어떤 위치에서든 리소스에 액세스할 수 있습니다.

→ `승인된 사용자` 조건 위반

### 2-6

키워드: 

- `조건1` S3 버킷, csv 파일 → 이미지 변환하여 그래픽 보고서 자동 생성,
- `조건2` 이미지는 1개월 후까지는 상관 없고, 1년에 두 번 ML 모델 교육을 위해 보관, 비용 효율적

단계 조합 2개

A. 매시간 해당 작업을 하는 것은 비용 효율적이지 않음

**B.** csv 파일→이미지 변환하여 S3버킷에 저장하는 Lambda 함수 이용 → `조건1` 충족

`조건2`를 위해 S3버킷의 csv 파일 및 이미지 파일에 대한 S3 수명 주기 규칙을 생성 (C,D,E)

C. [S3 Glacier](https://docs.aws.amazon.com/ko_kr/amazonglacier/latest/dev/introduction.html) : 데이터 보관 및 장기 백업을 목적

**D.** [S3 One Zone-IA](https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/storage-class-intro.html#sc-infreq-data-access) (Infrequent Access) : 수명이 길고 자주 액세스하지 않는 데이터용 

→ 1년에 두 번 정도로 자주 엑세스하지 않는 데이터이므로 D가 적합

E. S3 Standard-IA & 이미지 파일을 RRS (Reduced Redundancy Storage)에 보관

→ S3 One Zone-IA = S3 Standard-IA 

→ RRS는 자주 엑세스하는 객체를 위한 스토리지 클래스 ([링크](https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/storage-class-intro.html#sc-freq-data-access))

### 2-7

키워드: 콘텐츠 관리 웹 애플리케이션, ALB 뒤의 Auto Scaling 그룹 내의 EC2 인스턴스

지속적인 파일 업데이트, 모든 EC2 인스턴스 지연시간 최소화, 최신 콘텐츠 공유 솔루션

A. 가장 최근에 시작된 EC2 인스턴스 → 모든 EC2 인스턴스 조건 충족 X

**B.** 웹 사이트 자산을 [Amazon EFS](https://docs.aws.amazon.com/ko_kr/efs/latest/ug/whatisefs.html) 파일 시스템에 복사, EFS 파일 시스템을 로컬로 탑재하도록 각 EC2 인스턴스 구성 

→ 문제조건에서 지속적인 파일 업데이트가 발생하는데, Amazon EFS 특성 중 ‘사용자가 파일을 추가하고 제거할 때 자동으로 확장/축소되므로 데이터 증가에 맞춰 용량을 프로비저닝 및 관리할 필요가 없습니다.’ 와 잘 맞음

→ 각 EC2 인스턴스에 EFS 파일 시스템을 탑재하도록 구성하였으므로 모든 EC2 지연시간 최소화

C. 매시간 S3 sync 명령 → 지연시간 최소화 X

D. Amazon EBS 스냅샷 복원 → DB 복원과는 무관

### 2-8

키워드: AWS cloudtrail, S3 버킷 수명 정책

특정 AWS 계정에 cloudtrail 적용. cloudtrail 대상 S3 버킷은 S3 버전 관리 활성화.

S3 수명 주기 정책은 3년 후에 현재 객체를 삭제하는 것. (영문 해석)

4년 후 S3 버킷 지표가 보여주는 건 객체 수 증가했다는 것.

그러나 S3로 전달되는 새로운 Cloudtrail 로그의 수는 그대로.

비용 효율적으로 3년 이상 된 객체를 삭제할 솔루션?

**B**

→ S3 버킷의 수명이 3년 이상된 객체를 삭제하려면 S3 수명 주기 정책 사용하는 게 답 같아서 골랐습니다.

A,C → 비용적으로 비효율적일 것 같다는 생각

D → 삭제 자체가 이루어지지 않을 것 같음

### 2-9

키워드: NFS 볼륨, daily offsite backup

- 영문판 보면 A,B : 파일 게이트웨이 / C,D : 볼륨 게이트웨이

A.  [AWS 파일 게이트웨이](https://docs.aws.amazon.com/ko_kr/storagegateway/latest/userguide/StorageGatewayConcepts.html#file-gateway-concepts)를 온프레미스에 설치

**B.** [AWS 파일 게이트웨이](https://docs.aws.amazon.com/ko_kr/storagegateway/latest/userguide/StorageGatewayConcepts.html#file-gateway-concepts)를 하드웨어 어플라이언스에 설치

→ NFS 클라이언트에서 파일을 파일 게이트웨이에 기록하면 파일 게이트웨이가 파일의 데이터를 Amazon S3 업로드한 다음 메타데이터 (소유권, 타임스탬프 등) 가 옵니다. 파일 데이터를 업로드하면 S3 객체가 생성되고 파일의 메타데이터를 업로드하면 S3 객체의 메타데이터가 업데이트됩니다. 이 프로세스는 객체의 다른 버전을 작성하여 두 가지 버전의 객체를 만듭니다. S3 버전 관리가 활성화되면 두 버전 모두 저장됩니다.

→ 위 프로세스를 통해 오프사이드 백업본 생성 가능

→ A와 달리 또다른 하드웨어 어플라이언스에 설치해야 백업본 가능

C. [AWS  볼륨 게이트웨이](https://docs.aws.amazon.com/ko_kr/storagegateway/latest/userguide/StorageGatewayConcepts.html#volume-gateway-concepts)• [저장 볼륨 아키텍처](https://docs.aws.amazon.com/ko_kr/storagegateway/latest/userguide/StorageGatewayConcepts.html#storage-gateway-stored-volume-concepts)

→ 모든 애플리케이션 데이터를 온 프레미스 스토리지 하드웨어에 저장

D. [AWS  볼륨 게이트웨이](https://docs.aws.amazon.com/ko_kr/storagegateway/latest/userguide/StorageGatewayConcepts.html#volume-gateway-concepts) • [캐싱 볼륨 아키텍처](https://docs.aws.amazon.com/ko_kr/storagegateway/latest/userguide/StorageGatewayConcepts.html#storage-gateway-cached-concepts)

→캐시 볼륨으로 Amazon S3 기본 데이터 스토리지로 사용함과 동시에 자주 액세스하는 데이터를 스토리지 게이트웨이에 로컬에 보관할 수 있습니다.

### 2-10 <별>

키워드: 정적 이미지, 권한 있는 사용자만 S3 객체에 엑세스 가능, 데이터 손실 보호 솔루션

A. S3 버킷에서 버전 관리 활성화 → 데이터 손실 보호와 무관. 버전 관리(수명 주기 관리)는 비용 효율과 관련이라고 생각합니다..

**B.** S3 버킷에 대한 액세스 전환 → S3 객체에 대한 다른 리소스(버킷, 객체, 사용자) 의 권한을 부여함으로써 액세스 관리 ([링크](https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/example-walkthroughs-managing-access.html))

**C.** S3 버킷에서 [서버측 암호화](https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/serv-side-encryption.html) 활성화

→ B,C 중에 헷갈림,,

D. Amazon S3 Glacier → 데이터 백업 및 장기보존과는 무관함

**E.** [MFA](https://docs.aws.amazon.com/ko_kr/IAM/latest/UserGuide/id_credentials_mfa.html)(멀티 팩터 인증) 삭제를 사용하여 객체를 삭제하기 위해 다단계 인증 요구

→ 데이터 손실 보호에 올바른 솔루션

### 2-11

키워드: 로그는 S3 버킷에 저장. 단일 S3 버킷을 사용하는 중앙 집중식 로그 분석 솔루션

`운영 오버헤드 최소화`, `비용 효율적`

A. 버킷 중 하나 → `오버헤드` 발생

**B.** S3 동일 리전 복제. S3 버킷의 로그를 다른 리전 S3 버킷으로 복제. 복제한 S3 버킷을 로그 분석에 사용

→ 현재 한 리전에 배포되어 있으니까 다른 리전에 S3 버킷 복제 후 그 버킷을 로그 분석 용도로 사용한다.

C. 매일 API 작업으로 전체 버킷 내용 복사 → `비용 효율` X

D. 로그가 S3 버킷으로 전달될 때마다 트리거되는 계정에 Lambda 함수 → 전달될 떄마다 함수 발생시키는 것은 `오버헤드` & `비용 효율` X

### 2-12

키워드: `AMI`, 대규모 EC2 인스턴스 프로비저닝, Auto Scaling, `초기화 지연시간 최소화`

→ 수요가 증가함에 따라 새로운 AMI로 EC2 인스턴스를 새로 프로비저닝 해야하는데 이때 초기화하는 지연시간을 최소화할 수 있는 방안

A. [aws ec2 register-image](https://docs.aws.amazon.com/cli/latest/reference/ec2/register-image.html) : AMI로부터 인스턴스를 생성하고 시작할 때 마지막으로 해야하는 명령

[AWS Step functions](https://docs.aws.amazon.com/ko_kr/step-functions/latest/dg/welcome.html) : 단계적으로 워크플로의 각 단계의 상태를 검사하여 애플리케이션이 예상대로 순서대로 실행되는지 확인. 

→ 속도적인 면에서 불리

**B.** [Amazon EBS 빠른 스냅샷 복원](https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/ebs-fast-snapshot-restore.html) 활성화

→ 생성 시 완전히 초기화된 스냅샷에서 볼륨을 생성할 수 있습니다. 이렇게 하면 처음 액세스할 때 블록에 대한 I/O 작업 지연 시간이 없어집니다. 빠른 스냅샷 복원을 사용하여 생성된 볼륨은 프로비저닝된 모든 성능을 즉시 제공합니다.

→ 문제와 너무나도 찰떡인 설명

C. [Amazon DLM](https://docs.aws.amazon.com/ko_kr/dlm/latest/APIReference/Welcome.html) : AWS 리소스의 생명주기 관리 및 자동화 서비스

### 2-13

키워드: 공유 스토리지, SMB 클라이언트, 완전 관리형

A. [datasync](https://docs.aws.amazon.com/ko_kr/datasync/latest/userguide/what-is-datasync.html) : 데이터 이동을 단순화, 자동화 및 가속화는 온라인 데이터 전송 서비스

B. EC2 Windows 인스턴스 생성

→ SMB 클라이언트 사용 X

**C.** [Windows용 Amazon FSx 파일 서버](https://docs.aws.amazon.com/ko_kr/fsx/latest/WindowsGuide/what-is.html) 파일 시스템을 오리진 서버에 연결

→ 완전 관리형 Microsoft Windows 파일 서버를 제공

→ Windows 파일 시스템 기능을 기본적으로 지원하며 네트워크를 통해 파일 스토리지에 액세스할 수 있는 서버 메시지 블록(SMB) 프로토콜도 지원합니다.

애플리케이션 서버를 파일 시스템에 연결

→ 스토리지 공유

D. → SMB 클라이언트 X, 완전 관리형 X

### 2-14

키워드: Amazon S3 Standard. [멀티파트 업로드](https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/mpuoverview.html)로 자주 교체

 S3 객체의 수와 크기 일정, S3 비용 증가함. 비용 솔루션

A. [Amazon S3 Transfer Acceleration](https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/transfer-acceleration.html) → 속도가 빠른 대신 비용 비쌈

**B.** [불완전한 멀티파트 업로드를 삭제하는 S3 수명 주기 정책](https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/mpu-abort-incomplete-mpu-lifecycle-config.html) 

→ 저장 비용을 최소화하도록 수명 주기 규칙(`AbortIncompleteMultipartUpload`
 작업 사용)을 구성할 것을 권장합니다.

→ 문제와 딱 맞는 사례..!

C. 객체가 너무 빨리 아카이브 되지 않도록 S3 인벤토리 구성

 [S3 인벤토리 구성](https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/configure-inventory.html) : 객체 및 메타데이터 플랫 파일 목록을 제공

→ 인벤토리와는 무관

D. S3에 저장된 객체 수를 줄이기 → 객체 수와는 무관